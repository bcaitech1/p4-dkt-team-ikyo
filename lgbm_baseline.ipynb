{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LGBM Baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-24T09:49:29.375544Z",
     "start_time": "2021-05-24T09:49:28.999092Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import random\n",
    "import warnings\n",
    "import lightgbm as lgb\n",
    "from wandb.lightgbm import wandb_callback\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "import numpy as np\n",
    "import random\n",
    "from matplotlib import pylab as plt\n",
    "from lgbm_function import inference, set_params, custom_train_test_split\n",
    "from feature_engineering import feature_engineering\n",
    "from datetime import datetime\n",
    "import wandb\n",
    "\n",
    "%matplotlib inline\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. 데이터 로딩"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-24T09:49:29.678737Z",
     "start_time": "2021-05-24T09:49:29.376581Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2266586, 6)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userID</th>\n",
       "      <th>assessmentItemID</th>\n",
       "      <th>testId</th>\n",
       "      <th>answerCode</th>\n",
       "      <th>Timestamp</th>\n",
       "      <th>KnowledgeTag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>A060001001</td>\n",
       "      <td>A060000001</td>\n",
       "      <td>1</td>\n",
       "      <td>2020-03-24 00:17:11</td>\n",
       "      <td>7224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>A060001002</td>\n",
       "      <td>A060000001</td>\n",
       "      <td>1</td>\n",
       "      <td>2020-03-24 00:17:14</td>\n",
       "      <td>7225</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>A060001003</td>\n",
       "      <td>A060000001</td>\n",
       "      <td>1</td>\n",
       "      <td>2020-03-24 00:17:22</td>\n",
       "      <td>7225</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>A060001004</td>\n",
       "      <td>A060000001</td>\n",
       "      <td>1</td>\n",
       "      <td>2020-03-24 00:17:29</td>\n",
       "      <td>7225</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>A060001005</td>\n",
       "      <td>A060000001</td>\n",
       "      <td>1</td>\n",
       "      <td>2020-03-24 00:17:36</td>\n",
       "      <td>7225</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   userID assessmentItemID      testId  answerCode           Timestamp  \\\n",
       "0       0       A060001001  A060000001           1 2020-03-24 00:17:11   \n",
       "1       0       A060001002  A060000001           1 2020-03-24 00:17:14   \n",
       "2       0       A060001003  A060000001           1 2020-03-24 00:17:22   \n",
       "3       0       A060001004  A060000001           1 2020-03-24 00:17:29   \n",
       "4       0       A060001005  A060000001           1 2020-03-24 00:17:36   \n",
       "\n",
       "   KnowledgeTag  \n",
       "0          7224  \n",
       "1          7225  \n",
       "2          7225  \n",
       "3          7225  \n",
       "4          7225  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_dir = '/opt/ml/input/data/train_dataset'\n",
    "csv_file_path = os.path.join(data_dir, 'train_data.csv')\n",
    "df = pd.read_csv(csv_file_path, parse_dates=['Timestamp'])\n",
    "print(df.shape)\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-24T09:49:29.683739Z",
     "start_time": "2021-05-24T09:49:28.981Z"
    }
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "df = feature_engineering(df)\n",
    "df.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 유저별 분리\n",
    "train_lst, test_lst = custom_train_test_split(df)\n",
    "\n",
    "# 사용할 Feature 설정\n",
    "FEATS = [\"user_acc\", \"user_mean\", \"user_count\", \"user_correct_answer\", \"question_mean\", \"question_class_mean\"]\n",
    "\n",
    "# set parameters\n",
    "params = set_params()\n",
    "\n",
    "# \"test_sum\", \"question_class_count\", \"tag_sum\", \"question_count\", \"tag_mean\", \"test_mean\",\n",
    "\n",
    "for fold_num, (train, test) in enumerate(zip(train_lst, test_lst)):\n",
    "    print(\"@\"*50)\n",
    "    print(fold_num, \"번째 fold\")\n",
    "    print(\"@\"*50)\n",
    "    \n",
    "    # X, y 값 분리\n",
    "    y_train = train[\"answerCode\"]\n",
    "    train = train.drop([\"answerCode\"], axis=1)\n",
    "\n",
    "    y_test = test[\"answerCode\"]\n",
    "    test = test.drop([\"answerCode\"], axis=1)\n",
    "    \n",
    "    print(\"=\"*30)\n",
    "    print(\"train, test shape\")\n",
    "    print(train.shape, test.shape)\n",
    "    print(\"=\"*30)\n",
    "    print()\n",
    "    \n",
    "    lgb_train = lgb.Dataset(train[FEATS], y_train)\n",
    "    lgb_test = lgb.Dataset(test[FEATS], y_test)\n",
    "    \n",
    "    now = datetime.now()\n",
    "    wandb.init(project='P4-DKT', config=params, entity=\"team-ikyo\")\n",
    "    wandb.run.name = \"sun-lgbm-fold\" + str(fold_num) + \" time: \" + \" \".join(map(str, [now.month, now.day, now.hour, now.minute]))\n",
    "    \n",
    "    # train\n",
    "    model = lgb.train(params,\n",
    "                      lgb_train,\n",
    "                      valid_sets = [lgb_train, lgb_test],\n",
    "                      verbose_eval = 100,\n",
    "                      callbacks=[wandb_callback()])\n",
    "\n",
    "    preds = model.predict(test[FEATS])\n",
    "    acc = accuracy_score(y_test, np.where(preds >= 0.5, 1, 0))\n",
    "    auc = roc_auc_score(y_test, preds)\n",
    "\n",
    "    print(f'VALID AUC : {auc} ACC : {acc}\\n')\n",
    "    \n",
    "    # show feature importance\n",
    "    fig, ax = plt.subplots(figsize=(6,12))\n",
    "    lgb.plot_importance(model, max_num_features=100, height=0.8, ax=ax)\n",
    "    plt.show()\n",
    "    \n",
    "    # inference\n",
    "    inference(FEATS, model, auc, acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Result to csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception in thread Thread-7:\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.7/threading.py\", line 926, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/opt/conda/lib/python3.7/threading.py\", line 870, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/wandb/sdk/wandb_run.py\", line 180, in check_network_status\n",
      "    status_response = self._interface.communicate_network_status()\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/wandb/sdk/interface/interface.py\", line 747, in communicate_network_status\n",
      "    resp = self._communicate(req, timeout=timeout, local=True)\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/wandb/sdk/interface/interface.py\", line 537, in _communicate\n",
      "    return self._communicate_async(rec, local=local).get(timeout=timeout)\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/wandb/sdk/interface/interface.py\", line 542, in _communicate_async\n",
      "    raise Exception(\"The wandb backend process has shutdown\")\n",
      "Exception: The wandb backend process has shutdown\n",
      "\n",
      "Exception in thread Thread-6:\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.7/threading.py\", line 926, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/opt/conda/lib/python3.7/threading.py\", line 870, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/wandb/sdk/wandb_run.py\", line 198, in check_status\n",
      "    status_response = self._interface.communicate_stop_status()\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/wandb/sdk/interface/interface.py\", line 735, in communicate_stop_status\n",
      "    resp = self._communicate(req, timeout=timeout, local=True)\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/wandb/sdk/interface/interface.py\", line 537, in _communicate\n",
      "    return self._communicate_async(rec, local=local).get(timeout=timeout)\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/wandb/sdk/interface/interface.py\", line 542, in _communicate_async\n",
      "    raise Exception(\"The wandb backend process has shutdown\")\n",
      "Exception: The wandb backend process has shutdown\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from glob import glob\n",
    "import pandas as pd\n",
    "\n",
    "output_path = \"/opt/ml/code/output/cross_validation/output.csv\"\n",
    "csv_file_path_list = glob(\"/opt/ml/code/output/*.csv\")\n",
    "print(csv_file_path_list)\n",
    "\n",
    "# concat result dataframe\n",
    "result = pd.read_csv(csv_file_path_list[0])[\"prediction\"]\n",
    "for csv_file_path in csv_file_path_list[1:]:\n",
    "    result = pd.concat([result, pd.read_csv(csv_file_path)[\"prediction\"]], axis=1)\n",
    "\n",
    "# mean result dataframe\n",
    "result = pd.DataFrame(result.mean(axis=1)).reset_index().rename(columns = {0:\"prediction\", \"index\":\"id\"})\n",
    "result.to_csv(output_path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Grid Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 485,
   "metadata": {},
   "outputs": [],
   "source": [
    "FEATS = [\"user_correct_answer\", \"time_difference\",\n",
    "             \"user_acc\", \"test_mean\", \"test_sum\", \n",
    "             \"tag_mean\", \"tag_sum\", \"user_mean\", \"user_count\",\n",
    "             \"question_mean\", \"question_count\", \"question_class_mean\", \"question_class_count\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 488,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_FEATS = [[\"user_correct_answer\", \"time_difference\",\n",
    "             \"user_acc\", \"test_mean\", \"test_sum\", \n",
    "             \"tag_mean\", \"tag_sum\", \"user_mean\", \"user_count\",\n",
    "             \"question_mean\", \"question_count\", \"question_class_mean\", \"question_class_count\"]]\n",
    "\n",
    "for comb_num in range(6, 13, 2):\n",
    "    for features in list(combinations(FEATS, comb_num)):\n",
    "        grid_FEATS.append(list(features))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 367,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for FEATS in grid_FEATS:\n",
    "#     # 유저별 분리\n",
    "#     train, test = custom_train_test_split(df)\n",
    "\n",
    "#     # X, y 값 분리\n",
    "#     y_train = train['answerCode']\n",
    "#     train = train.drop(['answerCode'], axis=1)\n",
    "\n",
    "#     y_test = test['answerCode']\n",
    "#     test = test.drop(['answerCode'], axis=1)\n",
    "    \n",
    "#     params = {}\n",
    "#     params[\"boosting_type\"] = \"gbdt\" # gbdt, dart, goss\n",
    "#     params[\"learning_rate\"] = 1e-1 # 1e-1, 5e-2, 1e-2, 5e-3, 1e-3\n",
    "#     params[\"objective\"] = \"binary\"\n",
    "#     params[\"metric\"] = \"auc\" # binary_logloss, rmse, huber, auc\n",
    "#     params[\"num_iterations\"] = 1000 # 100\n",
    "#     params[\"max_depth\"] = 5 # -1\n",
    "#     params[\"num_leaves\"] = 10 # 31 이상적으로 num_leaves값은 2 ^ (max_depth) 값보다 적거나 같아야 합니다.\n",
    "#     params[\"min_data_in_leaf\"] = 10000 # 20 100 ~ 1000 수백 또는 수천 개로 정하는 것\n",
    "#     params[\"max_bin\"] = 16 # 256\n",
    "#     params[\"min_split_gain\"] = 1e-2 # ?\n",
    "#     params[\"scale_pos_weight\"] = 1.1 # 1.1~1.5\n",
    "#     params[\"tree_learner\"] = \"serial\" # serial, feature, data, voting\n",
    "#     params[\"early_stopping_rounds\"] = 50\n",
    "#     params[\"bagging_fraction\"] = 0.8 # 1.0\n",
    "#     params[\"lambda_l1\"] = 1e-1 # 0.0\n",
    "#     params[\"lambda_l2\"] = 1e-1 # 0.0\n",
    "\n",
    "#     print(\"=\"*30)\n",
    "#     print(\"=\"*30)\n",
    "#     print(FEATS)\n",
    "#     print(\"|\"*30)\n",
    "#     print(params)\n",
    "#     print(\"|\"*30)\n",
    "#     lgb_train = lgb.Dataset(train[FEATS], y_train)\n",
    "#     lgb_test = lgb.Dataset(test[FEATS], y_test)\n",
    "\n",
    "#     model = lgb.train(params,\n",
    "#                       lgb_train,\n",
    "#                       valid_sets = [lgb_train, lgb_test],\n",
    "#                       verbose_eval = 500)\n",
    "\n",
    "#     preds = model.predict(test[FEATS])\n",
    "#     acc = accuracy_score(y_test, np.where(preds >= 0.5, 1, 0))\n",
    "#     auc = roc_auc_score(y_test, preds)\n",
    "\n",
    "#     print(f'VALID AUC : {auc} ACC : {acc}\\n')\n",
    "\n",
    "#     # LOAD TESTDATA\n",
    "#     test_csv_file_path = os.path.join(data_dir, 'test_data.csv')\n",
    "#     test_df = pd.read_csv(test_csv_file_path, parse_dates=['Timestamp'])\n",
    "\n",
    "#     # FEATURE ENGINEERING\n",
    "#     test_df = feature_engineering(test_df)\n",
    "\n",
    "#     # LEAVE LAST INTERACTION ONLY\n",
    "#     test_df = test_df[test_df['userID'] != test_df['userID'].shift(-1)]\n",
    "\n",
    "#     # DROP ANSWERCODE\n",
    "#     test_df = test_df.drop(['answerCode'], axis=1)\n",
    "\n",
    "#     # MAKE PREDICTION\n",
    "#     total_preds = model.predict(test_df[FEATS])\n",
    "\n",
    "#     # SAVE OUTPUT\n",
    "#     output_dir = 'output/'\n",
    "#     write_path = os.path.join(output_dir, f\"lgbm/output_VALID_AUC_{round(auc, 4)}_ACC_{round(acc, 4)}.csv\")\n",
    "#     if not os.path.exists(output_dir):\n",
    "#         os.makedirs(output_dir)    \n",
    "#     with open(write_path, 'w', encoding='utf8') as w:\n",
    "#         print(\"writing prediction : {}\".format(write_path))\n",
    "#         w.write(\"id,prediction\\n\")\n",
    "#         for id, p in enumerate(total_preds):\n",
    "#             w.write('{},{}\\n'.format(id,p))\n",
    "#     print(\"=\"*30)\n",
    "#     print(\"=\"*30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
